{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographics API\n",
    "\n",
    "Below we have the code that retrieves the data from the  Mechanical Turk Tracker Demographics API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# This function takes as input the response for a single survey, and transforms it into a flat dictionary\n",
    "def flatten(item):\n",
    "    fmt = \"%Y-%m-%dT%H:%M:%S.%fZ\"\n",
    "    \n",
    "    hit_answer_date = datetime.strptime(item[\"date\"], fmt)\n",
    "    hit_creation_str = item.get(\"hitCreationDate\")\n",
    "    \n",
    "    if hit_creation_str is None: \n",
    "        hit_creation_date = None \n",
    "        diff = None\n",
    "    else:\n",
    "        hit_creation_date = datetime.strptime(hit_creation_str, fmt)\n",
    "        # convert to unix timestamp\n",
    "        hit_date_ts = time.mktime(hit_creation_date.timetuple())\n",
    "        answer_date_ts = time.mktime(hit_answer_date.timetuple())\n",
    "        diff = int(answer_date_ts-hit_date_ts)\n",
    "    \n",
    "    result = {\n",
    "        \"worker_id\": str(item[\"workerId\"]),\n",
    "        \"gender\": str(item[\"answers\"][\"gender\"]).lower(),\n",
    "        \"household_income\": str(item[\"answers\"][\"householdIncome\"]),\n",
    "        \"educational_level\": str(item[\"answers\"].get(\"educationalLevel\")),\n",
    "        \"household_size\": str(item[\"answers\"][\"householdSize\"]),\n",
    "        \"marital_status\": str(item[\"answers\"].get(\"maritalStatus\")),\n",
    "        \"languages_spoken\": str(item[\"answers\"].get(\"languagesSpoken\")),\n",
    "        \"time_spent_on_mturk\": str(item[\"answers\"].get(\"timeSpentOnMturk\")),\n",
    "        \"weekly_income_from_mturk\": str(item[\"answers\"].get(\"weeklyIncomeFromMturk\")),\n",
    "        \"year_of_birth\": int(item[\"answers\"][\"yearOfBirth\"]),\n",
    "        \"location_city\": str(item.get(\"locationCity\")),\n",
    "        \"location_region\": str(item.get(\"locationRegion\")),\n",
    "        \"location_country\": str(item[\"locationCountry\"]),\n",
    "        \"hit_answered_date\": hit_answer_date,\n",
    "        \"hit_creation_date\": hit_creation_date,\n",
    "        \"post_to_completion_secs\": diff\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved  5000  responses\n",
      "Total of  5000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  10000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  15000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  20000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  25000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  30000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  35000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  40000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  45000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  50000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  55000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  60000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  65000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  70000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  75000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  80000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  85000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  90000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  95000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  100000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  105000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  110000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  115000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  120000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  125000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  130000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  135000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  140000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  145000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  150000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  155000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  160000  responses in our data\n",
      "Retrieved  2685  responses\n",
      "Total of  162685  responses in our data\n"
     ]
    }
   ],
   "source": [
    "# The code below retrieves all the responses from the Demographics API\n",
    "# Since we cannot get all the responses at once, we fetch a few thousand\n",
    "# records at a time, until fetching them all\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "limit = 5000\n",
    "\n",
    "# The API call that returns the last survey responses\n",
    "baseurl = \"https://mturk-surveys.appspot.com/\" + \\\n",
    "    \"_ah/api/survey/v1/survey/demographics/answers?limit=\" + str(limit)\n",
    "\n",
    "# This is the cursor variable, used to retrieve more pages of results\n",
    "nextPageToken = None\n",
    "\n",
    "# We store the results in this list\n",
    "results = []\n",
    "\n",
    "while True:\n",
    "    if nextPageToken == None:\n",
    "        url = baseurl\n",
    "    else:\n",
    "        url = baseurl + \"&cursor=\" + nextPageToken\n",
    "\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code == 200:\n",
    "        data = json.loads(resp.text)\n",
    "        items = data.get(\"items\")\n",
    "        if items == None:\n",
    "            break\n",
    "        print(\"Retrieved \", len(items), \" responses\")\n",
    "        responses = [flatten(item) for item in items]\n",
    "        results.extend(responses)\n",
    "        print(\"Total of \", len(results), \" responses in our data\")\n",
    "    else:\n",
    "        print(\"Something went wrong with the network call\")\n",
    "\n",
    "    nextPageToken = data.get(\"nextPageToken\")\n",
    "    if nextPageToken == None:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162685\n"
     ]
    }
   ],
   "source": [
    "# Let's print the total number of retrieved responses\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "# Let's save the file as a CSV\n",
    "df.to_csv(\"mturk_surveys_extended.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['English', 'English', 'Malayalam', ..., 'None', 'None', 'None'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.languages_spoken.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " 'Abkhazian',\n",
       " 'Afar',\n",
       " 'Afrikaans',\n",
       " 'Albanian',\n",
       " 'Amharic',\n",
       " 'Arabic',\n",
       " 'Armenian',\n",
       " 'Assamese',\n",
       " 'Azerbaijani',\n",
       " 'Bashkir',\n",
       " 'Basque',\n",
       " 'Bengali',\n",
       " 'Bihari',\n",
       " 'Bulgarian',\n",
       " 'Burmese',\n",
       " 'Byelorussian',\n",
       " 'Cambodian',\n",
       " 'Catalan',\n",
       " 'Chinese',\n",
       " 'Croatian',\n",
       " 'Czech',\n",
       " 'Danish',\n",
       " 'Dutch',\n",
       " 'English',\n",
       " 'Esperanto',\n",
       " 'Estonian',\n",
       " 'Fiji',\n",
       " 'Finnish',\n",
       " 'French',\n",
       " 'Frisian',\n",
       " 'Gaelic',\n",
       " 'Galician',\n",
       " 'Georgian',\n",
       " 'German',\n",
       " 'Greek',\n",
       " 'Guarani',\n",
       " 'Gujarati',\n",
       " 'Hausa',\n",
       " 'Hebrew',\n",
       " 'Hindi',\n",
       " 'Hungarian',\n",
       " 'Icelandic',\n",
       " 'Indonesian',\n",
       " 'Interlingua',\n",
       " 'Irish',\n",
       " 'Italian',\n",
       " 'Japanese',\n",
       " 'Javanese',\n",
       " 'Kannada',\n",
       " 'Kashmiri',\n",
       " 'Korean',\n",
       " 'Kurdish',\n",
       " 'Laothian',\n",
       " 'Latin',\n",
       " 'Latvian',\n",
       " 'Lithuanian',\n",
       " 'Macedonian',\n",
       " 'Malagasy',\n",
       " 'Malay',\n",
       " 'Malayalam',\n",
       " 'Maltese',\n",
       " 'Marathi',\n",
       " 'Mongolian',\n",
       " 'Nepali',\n",
       " 'Norwegian',\n",
       " 'Oriya',\n",
       " 'Pashto',\n",
       " 'Persian',\n",
       " 'Polish',\n",
       " 'Portuguese',\n",
       " 'Punjabi',\n",
       " 'Romanian',\n",
       " 'Russian',\n",
       " 'Samoan',\n",
       " 'Sanskrit',\n",
       " 'Serbian',\n",
       " 'Serbo-Croatian',\n",
       " 'Shona',\n",
       " 'Sindhi',\n",
       " 'Singhalese',\n",
       " 'Slovak',\n",
       " 'Slovenian',\n",
       " 'Somali',\n",
       " 'Spanish',\n",
       " 'Swahili',\n",
       " 'Swedish',\n",
       " 'Tagalog',\n",
       " 'Tamil',\n",
       " 'Tatar',\n",
       " 'Tegulu',\n",
       " 'Thai',\n",
       " 'Tibetan',\n",
       " 'Turkish',\n",
       " 'Ukrainian',\n",
       " 'Urdu',\n",
       " 'Uzbek',\n",
       " 'Vietnamese',\n",
       " 'Welsh',\n",
       " 'Yiddish',\n",
       " 'Yoruba',\n",
       " 'Zulu'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol = [entries.split(',') for entries in df.languages_spoken.values if entries!='None']\n",
    "s = set()\n",
    "for l in lol:\n",
    "    for m in l:\n",
    "        s.add(m)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.people_with_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81618"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_with_language = len([v for v in df.languages_spoken.values if v!='None' and v!=''])\n",
    "people_with_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    118127\n",
       "IN     30253\n",
       "CA      2236\n",
       "GB      1564\n",
       "IT       699\n",
       "BR       610\n",
       "DE       609\n",
       "PH       514\n",
       "VE       465\n",
       "FR       438\n",
       "ES       344\n",
       "ZZ       322\n",
       "MX       301\n",
       "AU       249\n",
       "KE       208\n",
       "AE       193\n",
       "RO       178\n",
       "NL       174\n",
       "TR       171\n",
       "JP       163\n",
       "NG       162\n",
       "TH       156\n",
       "ID       152\n",
       "RU       150\n",
       "PT       147\n",
       "GR       142\n",
       "IE       138\n",
       "MK       134\n",
       "UA       119\n",
       "NZ       116\n",
       "       ...  \n",
       "AM         2\n",
       "TM         2\n",
       "BS         2\n",
       "SR         2\n",
       "RW         2\n",
       "LI         2\n",
       "AZ         2\n",
       "DJ         2\n",
       "MV         2\n",
       "PY         2\n",
       "MO         2\n",
       "SX         2\n",
       "NE         1\n",
       "IM         1\n",
       "AI         1\n",
       "FJ         1\n",
       "BM         1\n",
       "GN         1\n",
       "BU         1\n",
       "CN         1\n",
       "PF         1\n",
       "HT         1\n",
       "FM         1\n",
       "LA         1\n",
       "TZ         1\n",
       "PS         1\n",
       "AG         1\n",
       "GM         1\n",
       "CD         1\n",
       "UZ         1\n",
       "Name: location_country, Length: 156, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IN    7259\n",
       "US    6703\n",
       "CA     441\n",
       "IT     376\n",
       "BR     346\n",
       "DE     297\n",
       "GB     190\n",
       "FR     188\n",
       "ES     185\n",
       "VE     147\n",
       "MX     138\n",
       "RO      66\n",
       "NL      65\n",
       "PT      56\n",
       "KE      51\n",
       "PH      48\n",
       "CO      48\n",
       "RU      44\n",
       "JP      39\n",
       "AE      38\n",
       "GR      37\n",
       "EG      34\n",
       "MK      34\n",
       "AU      33\n",
       "TR      32\n",
       "BD      31\n",
       "BE      31\n",
       "NG      30\n",
       "BG      30\n",
       "LT      29\n",
       "      ... \n",
       "LK       5\n",
       "SV       5\n",
       "HU       4\n",
       "ZA       4\n",
       "KW       4\n",
       "MT       4\n",
       "CH       4\n",
       "NO       4\n",
       "LV       3\n",
       "JO       3\n",
       "SK       3\n",
       "NI       3\n",
       "IQ       3\n",
       "CY       3\n",
       "MD       2\n",
       "CW       2\n",
       "GE       2\n",
       "MN       2\n",
       "JM       2\n",
       "OM       2\n",
       "AL       2\n",
       "RW       1\n",
       "UG       1\n",
       "MU       1\n",
       "ME       1\n",
       "SR       1\n",
       "MV       1\n",
       "NA       1\n",
       "FM       1\n",
       "UY       1\n",
       "Name: location_country, Length: 106, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df [  df.languages_spoken.str.contains(',') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9115"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bilingual and above\n",
    "len(df [ df.languages_spoken.str.contains(',') ].worker_id.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bilingual'] = df.languages_spoken.str.contains(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>bilingual</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>perc_bilingual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location_country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LB</th>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BH</th>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BR</th>\n",
       "      <td>264.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>0.567213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DZ</th>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IT</th>\n",
       "      <td>323.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>0.537911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES</th>\n",
       "      <td>159.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.537791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG</th>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BO</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MV</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NI</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RW</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MN</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>312.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.487685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MX</th>\n",
       "      <td>163.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.458472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>60.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>250.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.429224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT</th>\n",
       "      <td>39.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.426471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CW</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BG</th>\n",
       "      <td>48.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT</th>\n",
       "      <td>91.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NL</th>\n",
       "      <td>109.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.373563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RO</th>\n",
       "      <td>112.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.370787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZW</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>47.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.356164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DO</th>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.340426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AG</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BB</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LU</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HT</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LI</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LC</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KZ</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KN</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KH</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JE</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DJ</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HN</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GY</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GU</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PS</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PY</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FJ</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DM</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KG</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "bilingual         False   True  perc_bilingual\n",
       "location_country                              \n",
       "FM                  0.0    1.0        1.000000\n",
       "LB                  5.0   17.0        0.772727\n",
       "BH                 14.0   21.0        0.600000\n",
       "TN                  6.0    8.0        0.571429\n",
       "BR                264.0  346.0        0.567213\n",
       "DZ                 16.0   20.0        0.555556\n",
       "IT                323.0  376.0        0.537911\n",
       "ES                159.0  185.0        0.537791\n",
       "EG                 33.0   34.0        0.507463\n",
       "BO                  5.0    5.0        0.500000\n",
       "ME                  1.0    1.0        0.500000\n",
       "MA                 18.0   18.0        0.500000\n",
       "MV                  1.0    1.0        0.500000\n",
       "NI                  3.0    3.0        0.500000\n",
       "RW                  1.0    1.0        0.500000\n",
       "SR                  1.0    1.0        0.500000\n",
       "MN                  2.0    2.0        0.500000\n",
       "DE                312.0  297.0        0.487685\n",
       "MX                163.0  138.0        0.458472\n",
       "CO                 60.0   48.0        0.444444\n",
       "FR                250.0  188.0        0.429224\n",
       "LT                 39.0   29.0        0.426471\n",
       "CW                  3.0    2.0        0.400000\n",
       "BG                 48.0   30.0        0.384615\n",
       "PT                 91.0   56.0        0.380952\n",
       "NL                109.0   65.0        0.373563\n",
       "RO                112.0   66.0        0.370787\n",
       "ZW                  9.0    5.0        0.357143\n",
       "AR                 47.0   26.0        0.356164\n",
       "DO                 31.0   16.0        0.340426\n",
       "...                 ...    ...             ...\n",
       "AG                  1.0    0.0        0.000000\n",
       "BB                  6.0    0.0        0.000000\n",
       "CN                  1.0    0.0        0.000000\n",
       "LU                 11.0    0.0        0.000000\n",
       "HT                  1.0    0.0        0.000000\n",
       "LI                  2.0    0.0        0.000000\n",
       "LC                  8.0    0.0        0.000000\n",
       "LA                  1.0    0.0        0.000000\n",
       "KZ                  3.0    0.0        0.000000\n",
       "NE                  1.0    0.0        0.000000\n",
       "KN                  7.0    0.0        0.000000\n",
       "KH                 19.0    0.0        0.000000\n",
       "AF                  8.0    0.0        0.000000\n",
       "JE                  3.0    0.0        0.000000\n",
       "IS                  5.0    0.0        0.000000\n",
       "IM                  1.0    0.0        0.000000\n",
       "PF                  1.0    0.0        0.000000\n",
       "DJ                  2.0    0.0        0.000000\n",
       "HN                 28.0    0.0        0.000000\n",
       "GY                  8.0    0.0        0.000000\n",
       "GU                  4.0    0.0        0.000000\n",
       "GN                  1.0    0.0        0.000000\n",
       "PS                  1.0    0.0        0.000000\n",
       "GM                  1.0    0.0        0.000000\n",
       "PY                  2.0    0.0        0.000000\n",
       "GD                  5.0    0.0        0.000000\n",
       "FJ                  1.0    0.0        0.000000\n",
       "ET                  3.0    0.0        0.000000\n",
       "DM                 17.0    0.0        0.000000\n",
       "KG                  4.0    0.0        0.000000\n",
       "\n",
       "[156 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pv_bilingual = df.pivot_table(\n",
    "    index = 'location_country',\n",
    "    columns='bilingual',\n",
    "    values = 'worker_id',\n",
    "    aggfunc='count'\n",
    ").fillna(0)\n",
    "\n",
    "pv_bilingual['perc_bilingual'] = pv_bilingual[True] / (pv_bilingual[True] + pv_bilingual[False])\n",
    "pv_bilingual.sort_values('perc_bilingual', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38559"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique ids of workers that answered the language question\n",
    "len(df [ df.languages_spoken !='None' ].worker_id.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    56937\n",
       "IN    15221\n",
       "CA     1302\n",
       "GB      977\n",
       "IT      416\n",
       "BR      385\n",
       "DE      356\n",
       "VE      221\n",
       "PH      220\n",
       "ES      208\n",
       "FR      198\n",
       "MX      163\n",
       "ZZ      156\n",
       "KE      132\n",
       "AU      130\n",
       "NL      101\n",
       "NG       83\n",
       "TH       80\n",
       "JP       78\n",
       "IE       77\n",
       "RO       74\n",
       "UA       71\n",
       "ID       69\n",
       "PT       66\n",
       "AE       65\n",
       "CO       60\n",
       "TR       59\n",
       "RU       51\n",
       "BD       51\n",
       "PK       47\n",
       "      ...  \n",
       "ZM        2\n",
       "CM        2\n",
       "RW        2\n",
       "AL        2\n",
       "NA        2\n",
       "SX        2\n",
       "TJ        2\n",
       "GD        2\n",
       "GY        2\n",
       "MD        2\n",
       "KG        2\n",
       "ME        2\n",
       "JE        2\n",
       "TM        2\n",
       "GN        1\n",
       "AM        1\n",
       "MV        1\n",
       "KN        1\n",
       "BN        1\n",
       "UZ        1\n",
       "MU        1\n",
       "MO        1\n",
       "DJ        1\n",
       "UY        1\n",
       "NE        1\n",
       "FM        1\n",
       "LU        1\n",
       "BY        1\n",
       "ET        1\n",
       "SR        1\n",
       "Name: location_country, Length: 134, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df [  df.languages_spoken.str.contains('English') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IN    6202\n",
       "US      96\n",
       "AE      21\n",
       "CA      12\n",
       "GB      11\n",
       "ZZ       9\n",
       "SA       8\n",
       "FR       4\n",
       "AU       4\n",
       "QA       4\n",
       "NO       3\n",
       "DE       3\n",
       "BH       3\n",
       "SG       2\n",
       "KW       2\n",
       "LK       2\n",
       "UA       2\n",
       "PL       2\n",
       "IQ       1\n",
       "CZ       1\n",
       "HK       1\n",
       "NG       1\n",
       "JP       1\n",
       "MV       1\n",
       "SE       1\n",
       "OM       1\n",
       "MY       1\n",
       "IT       1\n",
       "PK       1\n",
       "CO       1\n",
       "Name: location_country, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df [  df.languages_spoken.str.contains('Tamil') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    3565\n",
       "ES     193\n",
       "IN     192\n",
       "VE     169\n",
       "BR     160\n",
       "MX     139\n",
       "IT      75\n",
       "CO      49\n",
       "CA      48\n",
       "GB      44\n",
       "FR      36\n",
       "DE      30\n",
       "PR      29\n",
       "PT      27\n",
       "AR      26\n",
       "DO      18\n",
       "CL      18\n",
       "PE      17\n",
       "EC      15\n",
       "BE      14\n",
       "NL      11\n",
       "JP      11\n",
       "ZZ       9\n",
       "GR       8\n",
       "CR       8\n",
       "PA       7\n",
       "SV       7\n",
       "MA       6\n",
       "TT       6\n",
       "TH       6\n",
       "      ... \n",
       "KR       3\n",
       "TR       3\n",
       "MT       3\n",
       "QA       2\n",
       "SE       2\n",
       "EE       2\n",
       "BG       2\n",
       "JM       2\n",
       "TW       2\n",
       "JO       2\n",
       "UA       2\n",
       "CW       2\n",
       "CH       2\n",
       "RU       2\n",
       "LB       2\n",
       "UY       2\n",
       "PH       2\n",
       "MD       1\n",
       "BD       1\n",
       "MY       1\n",
       "SA       1\n",
       "PK       1\n",
       "CZ       1\n",
       "AE       1\n",
       "AL       1\n",
       "BH       1\n",
       "MK       1\n",
       "FI       1\n",
       "RS       1\n",
       "NP       1\n",
       "Name: location_country, Length: 72, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df [  df.languages_spoken.str.contains('Spanish') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IN    2930\n",
       "US     185\n",
       "CA      31\n",
       "AE      29\n",
       "BD      21\n",
       "GB      19\n",
       "SA      11\n",
       "SE       9\n",
       "NP       9\n",
       "BR       7\n",
       "DE       7\n",
       "PH       6\n",
       "PK       5\n",
       "IT       5\n",
       "UA       4\n",
       "BH       4\n",
       "NO       3\n",
       "KW       3\n",
       "QA       3\n",
       "NZ       3\n",
       "JP       2\n",
       "SG       2\n",
       "HK       2\n",
       "AU       2\n",
       "KR       2\n",
       "OM       2\n",
       "DK       1\n",
       "ID       1\n",
       "IQ       1\n",
       "GH       1\n",
       "ZZ       1\n",
       "Name: location_country, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df [  df.languages_spoken.str.contains('Hindi') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    878\n",
       "CA    289\n",
       "FR    209\n",
       "IN    186\n",
       "IT     64\n",
       "DE     63\n",
       "GB     63\n",
       "BE     30\n",
       "ES     26\n",
       "KE     22\n",
       "NG     20\n",
       "EG     20\n",
       "MA     18\n",
       "DZ     18\n",
       "BR     18\n",
       "BH     17\n",
       "NL     15\n",
       "IE     12\n",
       "PT     10\n",
       "RO      8\n",
       "TN      8\n",
       "TR      5\n",
       "PA      5\n",
       "VE      5\n",
       "RS      4\n",
       "JP      4\n",
       "MX      4\n",
       "IL      4\n",
       "CO      4\n",
       "GH      4\n",
       "     ... \n",
       "BD      2\n",
       "AR      2\n",
       "BG      2\n",
       "FI      2\n",
       "SA      2\n",
       "CH      2\n",
       "QA      2\n",
       "BA      1\n",
       "AL      1\n",
       "DO      1\n",
       "UG      1\n",
       "HK      1\n",
       "PL      1\n",
       "MT      1\n",
       "RU      1\n",
       "RW      1\n",
       "AU      1\n",
       "AE      1\n",
       "IQ      1\n",
       "CR      1\n",
       "FM      1\n",
       "MU      1\n",
       "NI      1\n",
       "MD      1\n",
       "UA      1\n",
       "CZ      1\n",
       "ID      1\n",
       "JO      1\n",
       "PK      1\n",
       "AT      1\n",
       "Name: location_country, Length: 66, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df [  df.languages_spoken.str.contains('French') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IN    1550\n",
       "AE      28\n",
       "US      24\n",
       "SA      10\n",
       "CA       6\n",
       "QA       4\n",
       "GB       3\n",
       "BH       3\n",
       "KW       3\n",
       "OM       2\n",
       "ZZ       2\n",
       "IQ       1\n",
       "CO       1\n",
       "GT       1\n",
       "BN       1\n",
       "MV       1\n",
       "Name: location_country, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df [  df.languages_spoken.str.contains('Malayalam') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IN    715\n",
       "US     31\n",
       "GB      7\n",
       "SE      3\n",
       "ZZ      2\n",
       "PL      2\n",
       "AU      1\n",
       "CA      1\n",
       "FR      1\n",
       "JP      1\n",
       "ID      1\n",
       "BH      1\n",
       "Name: location_country, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df [  df.languages_spoken.str.contains('Tegulu') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    418\n",
       "DE    304\n",
       "IN     48\n",
       "GB     30\n",
       "IT     28\n",
       "FR     19\n",
       "BE     18\n",
       "NL     17\n",
       "ES     16\n",
       "IE     12\n",
       "LB     12\n",
       "CA     11\n",
       "FI     10\n",
       "AT      9\n",
       "CO      6\n",
       "MX      6\n",
       "DK      5\n",
       "TR      5\n",
       "AU      4\n",
       "BR      4\n",
       "HR      4\n",
       "MK      3\n",
       "TH      3\n",
       "GR      2\n",
       "AR      2\n",
       "RO      2\n",
       "VE      2\n",
       "SI      2\n",
       "ZZ      1\n",
       "SV      1\n",
       "CH      1\n",
       "PL      1\n",
       "NO      1\n",
       "BA      1\n",
       "KE      1\n",
       "AL      1\n",
       "LT      1\n",
       "JP      1\n",
       "GT      1\n",
       "BO      1\n",
       "PH      1\n",
       "TN      1\n",
       "VN      1\n",
       "EG      1\n",
       "ID      1\n",
       "ZA      1\n",
       "SE      1\n",
       "CY      1\n",
       "RS      1\n",
       "Name: location_country, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df [  df.languages_spoken.str.contains('German') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MN    0.250000\n",
       "HK    0.250000\n",
       "MY    0.212121\n",
       "TW    0.146341\n",
       "DK    0.085714\n",
       "KR    0.053333\n",
       "LV    0.043478\n",
       "SG    0.037383\n",
       "CA    0.036673\n",
       "GH    0.033333\n",
       "AU    0.020080\n",
       "ZA    0.014706\n",
       "AR    0.013699\n",
       "ID    0.013158\n",
       "JP    0.012270\n",
       "NL    0.011494\n",
       "BE    0.010204\n",
       "MX    0.009967\n",
       "PK    0.009709\n",
       "ES    0.008721\n",
       "NZ    0.008621\n",
       "PH    0.007782\n",
       "IT    0.007153\n",
       "GB    0.007033\n",
       "TH    0.006410\n",
       "ZZ    0.006211\n",
       "US    0.005790\n",
       "AE    0.005181\n",
       "DE    0.004926\n",
       "FR    0.004566\n",
       "        ...   \n",
       "PT         NaN\n",
       "PY         NaN\n",
       "QA         NaN\n",
       "RO         NaN\n",
       "RS         NaN\n",
       "RU         NaN\n",
       "RW         NaN\n",
       "SA         NaN\n",
       "SE         NaN\n",
       "SI         NaN\n",
       "SK         NaN\n",
       "SR         NaN\n",
       "SV         NaN\n",
       "SX         NaN\n",
       "TJ         NaN\n",
       "TM         NaN\n",
       "TN         NaN\n",
       "TR         NaN\n",
       "TT         NaN\n",
       "TZ         NaN\n",
       "UA         NaN\n",
       "UG         NaN\n",
       "UY         NaN\n",
       "UZ         NaN\n",
       "VC         NaN\n",
       "VE         NaN\n",
       "VI         NaN\n",
       "VN         NaN\n",
       "ZM         NaN\n",
       "ZW         NaN\n",
       "Name: location_country, Length: 156, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df [  df.languages_spoken.str.contains('Chinese') ].location_country.value_counts() / df.location_country.value_counts()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MK    39\n",
       "RS     4\n",
       "US     2\n",
       "BA     2\n",
       "IT     1\n",
       "Name: location_country, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df [  df.languages_spoken.str.contains('Macedonian') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = set([l for v in df.languages_spoken.values if v!='None' \n",
    "                 for l in v.split(',') if l!=''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            lang  unique_workers\n",
      "78       English           37984\n",
      "52       Spanish            3063\n",
      "10         Tamil            2496\n",
      "61         Hindi            1494\n",
      "23        French            1265\n",
      "89         Malay             687\n",
      "19        German             673\n",
      "39     Malayalam             667\n",
      "49       Chinese             568\n",
      "1        Italian             537\n",
      "44    Portuguese             479\n",
      "27        Tegulu             328\n",
      "81      Japanese             249\n",
      "68       Russian             235\n",
      "24        Arabic             227\n",
      "55       Kannada             174\n",
      "73        Korean             162\n",
      "86       Tagalog             159\n",
      "76          Urdu             131\n",
      "17    Vietnamese             112\n",
      "38       Marathi             109\n",
      "14         Dutch             105\n",
      "91      Gujarati             102\n",
      "21       Bengali              96\n",
      "56       Punjabi              90\n",
      "74        Polish              84\n",
      "53       Turkish              75\n",
      "59      Romanian              65\n",
      "64         Greek              61\n",
      "34        Hebrew              44\n",
      "..           ...             ...\n",
      "72       Latvian               5\n",
      "93      Assamese               5\n",
      "83        Gaelic               5\n",
      "18        Pashto               4\n",
      "2         Somali               4\n",
      "51        Samoan               3\n",
      "32     Icelandic               3\n",
      "47         Tatar               3\n",
      "62     Mongolian               3\n",
      "3   Byelorussian               2\n",
      "98       Yiddish               2\n",
      "50      Georgian               2\n",
      "25         Uzbek               2\n",
      "77      Malagasy               2\n",
      "42       Amharic               2\n",
      "35         Hausa               2\n",
      "26       Maltese               1\n",
      "99          Zulu               1\n",
      "33          Fiji               1\n",
      "95   Interlingua               1\n",
      "31       Frisian               1\n",
      "80       Guarani               1\n",
      "8      Abkhazian               1\n",
      "63   Azerbaijani               1\n",
      "67       Burmese               1\n",
      "69         Shona               1\n",
      "13       Bashkir               1\n",
      "9         Basque               1\n",
      "4           Afar               1\n",
      "15       Tibetan               1\n",
      "\n",
      "[101 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = []\n",
    "for language in languages:\n",
    "    people = len(set(df[ df.languages_spoken.str.contains(language) ].worker_id.values))\n",
    "    result.append({\"lang\":language, \"unique_workers\": people})\n",
    "    \n",
    "\n",
    "df_cnt = pd.DataFrame(result).sort_values('unique_workers', ascending=False)    \n",
    "print (df_cnt)    \n",
    "# more than 10 people for the language\n",
    "\n",
    "#df2 = pd.DataFrame(result).sort_values('unique_workers', ascending=False)\n",
    "#enough = df2 [df2.unique_workers > 9]\n",
    "#len(enough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        14\n",
       "2         7\n",
       "3         4\n",
       "4         2\n",
       "5         4\n",
       "6         6\n",
       "7         1\n",
       "8         1\n",
       "9         1\n",
       "10        1\n",
       "11        1\n",
       "12        1\n",
       "13        2\n",
       "14        2\n",
       "15        2\n",
       "16        2\n",
       "17        1\n",
       "19        1\n",
       "20        1\n",
       "21        2\n",
       "22        2\n",
       "23        1\n",
       "24        3\n",
       "25        3\n",
       "27        1\n",
       "30        1\n",
       "33        1\n",
       "36        1\n",
       "39        1\n",
       "41        1\n",
       "44        1\n",
       "61        1\n",
       "65        1\n",
       "75        1\n",
       "84        1\n",
       "90        1\n",
       "96        1\n",
       "102       1\n",
       "105       1\n",
       "109       1\n",
       "112       1\n",
       "131       1\n",
       "159       1\n",
       "162       1\n",
       "174       1\n",
       "227       1\n",
       "235       1\n",
       "249       1\n",
       "328       1\n",
       "479       1\n",
       "537       1\n",
       "568       1\n",
       "667       1\n",
       "673       1\n",
       "687       1\n",
       "1265      1\n",
       "1494      1\n",
       "2496      1\n",
       "3063      1\n",
       "37984     1\n",
       "Name: unique_workers, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnt.unique_workers.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5044"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([v for v in df.languages_spoken.values if 'Spanish' in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10490.450487855513"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1189 / 19268 * 170000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def intersect(a, b):\n",
    "    \"\"\" return the intersection of two lists \"\"\"\n",
    "    return list(set(a) & set(b))\n",
    "\n",
    "my_langauge = ['English', 'Tamil', 'Spanish', 'Hindi', 'Malayalam', 'French', 'Telugu', 'Chinese', 'German', 'Kannada', 'Italian', 'Portuguese', 'Marathi', 'Arabic', 'Russian', 'Japanese', 'Gujarati', 'Urdu', 'Bengali', 'Punjabi', 'Korean', 'Tagalog', 'Romanian', 'Vietnamese', 'Greek', 'Polish', 'Dutch', 'Turkish', 'Hebrew', 'Swedish', 'Serbian', 'Nepali', 'Bulgarian', 'Macedonian', 'Oriya']\n",
    "pavlick_langauge = ['English', 'Tamil', 'Malayalam', 'Hindi', 'Spanish', 'Telugu', 'Chinese', 'Romanian', 'Portuguese', 'Arabic', 'Kannada', 'German', 'French', 'Polish', 'Urdu', 'Tagalog', 'Marathi', 'Russian', 'Italian', 'Bengali', 'Gujarati', 'Hebrew', 'Dutch', 'Turkish', 'Vietnamese', 'Macedonian', 'Cebuano', 'Swedish', 'Bulgarian', 'Swahili', 'Hungarian', 'Catalan', 'Thai', 'Lithuanian', 'Punjabi']\n",
    "\n",
    "intersect_language = intersect(my_langauge, pavlick_langauge)\n",
    "len(intersect_language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/stats/stats.py:245: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.057703081232493, pvalue=0.7419647128381073)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(my_langauge,pavlick_langauge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
