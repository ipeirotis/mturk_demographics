{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvXHTj1G2upY"
      },
      "source": [
        "### Demographics API\n",
        "\n",
        "Below we have the code that retrieves the data from the  Mechanical Turk Tracker Demographics API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtAmJhhw2upd"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# This function takes as input the response for a single survey, and transforms it into a flat dictionary\n",
        "def flatten(item):\n",
        "    fmt = \"%Y-%m-%dT%H:%M:%S.%f%z\"\n",
        "    \n",
        "    hit_answer_date = datetime.strptime(item[\"date\"], fmt)\n",
        "    hit_creation_str = item.get(\"hitCreationDate\")\n",
        "    \n",
        "    if hit_creation_str is None: \n",
        "        hit_creation_date = None \n",
        "        diff = None\n",
        "    else:\n",
        "        hit_creation_date = datetime.strptime(hit_creation_str, fmt)\n",
        "        # convert to unix timestamp\n",
        "        hit_date_ts = time.mktime(hit_creation_date.timetuple())\n",
        "        answer_date_ts = time.mktime(hit_answer_date.timetuple())\n",
        "        diff = int(answer_date_ts-hit_date_ts)\n",
        "    \n",
        "    result = {\n",
        "        \"worker_id\": str(item[\"workerId\"]),\n",
        "        \"gender\": str(item[\"answers\"][\"gender\"]).lower(),\n",
        "        \"household_income\": str(item[\"answers\"][\"householdIncome\"]),\n",
        "        \"educational_level\": str(item[\"answers\"].get(\"educationalLevel\")),\n",
        "        \"household_size\": str(item[\"answers\"][\"householdSize\"]),\n",
        "        \"marital_status\": str(item[\"answers\"].get(\"maritalStatus\")),\n",
        "        \"languages_spoken\": str(item[\"answers\"].get(\"languagesSpoken\")),\n",
        "        \"time_spent_on_mturk\": str(item[\"answers\"].get(\"timeSpentOnMturk\")),\n",
        "        \"weekly_income_from_mturk\": str(item[\"answers\"].get(\"weeklyIncomeFromMturk\")),\n",
        "        \"year_of_birth\": int(item[\"answers\"][\"yearOfBirth\"]),\n",
        "        \"location_city\": str(item.get(\"locationCity\")),\n",
        "        \"location_region\": str(item.get(\"locationRegion\")),\n",
        "        \"location_country\": str(item[\"locationCountry\"]),\n",
        "        \"hit_answered_date\": hit_answer_date,\n",
        "        \"hit_creation_date\": hit_creation_date,\n",
        "        \"post_to_completion_secs\": diff\n",
        "    }\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDEMHSqK2upf"
      },
      "outputs": [],
      "source": [
        "# The code below retrieves all the responses from the Demographics API\n",
        "# Since we cannot get all the responses at once, we fetch a few thousand\n",
        "# records at a time, until fetching them all\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "limit = 1000\n",
        "\n",
        "# The API call that returns the last survey responses\n",
        "# The API call that returns the last survey responses\n",
        "baseurl = \"https://demographics.mturk-tracker.com\" + \\\n",
        "    \"/api/survey/demographics/answers?limit=\" + str(limit)\n",
        "\n",
        "# This is the cursor variable, used to retrieve more pages of results\n",
        "nextPageToken = \"\"\n",
        "\n",
        "# We store the results in this list\n",
        "results = []\n",
        "\n",
        "while True:\n",
        "\n",
        "    url = baseurl + \"&cursor=\" + nextPageToken\n",
        "\n",
        "    resp = requests.get(url)\n",
        "    if resp.status_code == 200:\n",
        "        data = json.loads(resp.text)\n",
        "        items = data.get(\"items\")\n",
        "        if items == None:\n",
        "            break\n",
        "        print(\"Retrieved \", len(items), \" responses\")\n",
        "        responses = [flatten(item) for item in items]\n",
        "        results.extend(responses)\n",
        "        print(\"Total of \", len(results), \" responses in our data\")\n",
        "    else:\n",
        "        print(\"Something went wrong with the network call\")\n",
        "\n",
        "    nextPageToken = data.get(\"nextPageToken\")\n",
        "    if nextPageToken == None:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bTbQ8Yv2uph"
      },
      "outputs": [],
      "source": [
        "# Let's print the total number of retrieved responses\n",
        "print(len(results))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch the old data as well (Mar 2015 - Oct 2020)\n",
        "URL = 'https://github.com/ipeirotis/mturk_demographics/raw/master/mturk_surveys_extended_mar15_oct20.zip'\n",
        "df_old = pd.read_csv(URL)\n",
        "df_old = df_old.drop('Unnamed: 0', axis='columns')\n",
        "df_old"
      ],
      "metadata": {
        "id": "B-Gbh7GA4aqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riwPRPOc2uph"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(results)\n",
        "df = pd.concat([df, df_old])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "gn1JKrEK4U8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's save the file as a CSV\n",
        "df.to_csv(\"mturk_surveys_extended.csv\")"
      ],
      "metadata": {
        "id": "Dp5saulK36-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7UcXyx32upi"
      },
      "outputs": [],
      "source": [
        "df.languages_spoken.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZDGcb3V2upi"
      },
      "outputs": [],
      "source": [
        "lol = [entries.split(',') for entries in df.languages_spoken.values if entries!='None']\n",
        "s = set()\n",
        "for l in lol:\n",
        "    for m in l:\n",
        "        s.add(m)\n",
        "s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74feKaML2upj"
      },
      "outputs": [],
      "source": [
        "people_with_language = len([v for v in df.languages_spoken.values if v!='None' and v!=''])\n",
        "people_with_language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXEx6g9o2upj"
      },
      "outputs": [],
      "source": [
        "df.location_country.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0NV-BeF2upk"
      },
      "outputs": [],
      "source": [
        "df [  df.languages_spoken.str.contains(',') ].location_country.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rE-7powG2upk"
      },
      "outputs": [],
      "source": [
        "# bilingual and above\n",
        "len(df [ df.languages_spoken.str.contains(',') ].worker_id.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITuIWjkU2upl"
      },
      "outputs": [],
      "source": [
        "df['bilingual'] = df.languages_spoken.str.contains(',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_XrONtF2upl"
      },
      "outputs": [],
      "source": [
        "pv_bilingual = df.pivot_table(\n",
        "    index = 'location_country',\n",
        "    columns='bilingual',\n",
        "    values = 'worker_id',\n",
        "    aggfunc='count'\n",
        ").fillna(0)\n",
        "\n",
        "pv_bilingual['perc_bilingual'] = pv_bilingual[True] / (pv_bilingual[True] + pv_bilingual[False])\n",
        "pv_bilingual.sort_values('perc_bilingual', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0SXO4O92upl"
      },
      "outputs": [],
      "source": [
        "# unique ids of workers that answered the language question\n",
        "len(df [ df.languages_spoken !='None' ].worker_id.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woM9Oe2Q2upm"
      },
      "outputs": [],
      "source": [
        "df [  df.languages_spoken.str.contains('English') ].location_country.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "GyLYFwd62upm"
      },
      "outputs": [],
      "source": [
        "df [  df.languages_spoken.str.contains('Tamil') ].location_country.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKDFqdGv2upm"
      },
      "outputs": [],
      "source": [
        "df [  df.languages_spoken.str.contains('Spanish') ].location_country.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HVybNlX2upn"
      },
      "outputs": [],
      "source": [
        "df [  df.languages_spoken.str.contains('Hindi') ].location_country.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtRtLszZ2upn"
      },
      "outputs": [],
      "source": [
        "df [  df.languages_spoken.str.contains('French') ].location_country.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8b25sB32upn"
      },
      "outputs": [],
      "source": [
        "df [  df.languages_spoken.str.contains('Malayalam') ].location_country.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqaSozNH2upn"
      },
      "outputs": [],
      "source": [
        "df [  df.languages_spoken.str.contains('Tegulu') ].location_country.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1QhEM8Q2upo"
      },
      "outputs": [],
      "source": [
        "df [  df.languages_spoken.str.contains('German') ].location_country.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZxqzlxr2upo"
      },
      "outputs": [],
      "source": [
        "(df [  df.languages_spoken.str.contains('Chinese') ].location_country.value_counts() / df.location_country.value_counts()).sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbjMJ7892upo"
      },
      "outputs": [],
      "source": [
        "df [  df.languages_spoken.str.contains('Macedonian') ].location_country.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKv0wqxL2upo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIESLCZF2upo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlLRSio_2upo"
      },
      "outputs": [],
      "source": [
        "languages = set([l for v in df.languages_spoken.values if v!='None' \n",
        "                 for l in v.split(',') if l!=''])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4txAb4N2upp"
      },
      "outputs": [],
      "source": [
        "\n",
        "result = []\n",
        "for language in languages:\n",
        "    people = len(set(df[ df.languages_spoken.str.contains(language) ].worker_id.values))\n",
        "    result.append({\"lang\":language, \"unique_workers\": people})\n",
        "    \n",
        "\n",
        "df_cnt = pd.DataFrame(result).sort_values('unique_workers', ascending=False)    \n",
        "print (df_cnt)    \n",
        "# more than 10 people for the language\n",
        "\n",
        "#df2 = pd.DataFrame(result).sort_values('unique_workers', ascending=False)\n",
        "#enough = df2 [df2.unique_workers > 9]\n",
        "#len(enough)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1CESk_L2upp"
      },
      "outputs": [],
      "source": [
        "df_cnt.unique_workers.value_counts().sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79HpWESU2upp"
      },
      "outputs": [],
      "source": [
        "len([v for v in df.languages_spoken.values if 'Spanish' in v])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DpC61cS2upp"
      },
      "outputs": [],
      "source": [
        "1189 / 19268 * 170000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMph3GbI2upp"
      },
      "outputs": [],
      "source": [
        "def intersect(a, b):\n",
        "    \"\"\" return the intersection of two lists \"\"\"\n",
        "    return list(set(a) & set(b))\n",
        "\n",
        "my_langauge = ['English', 'Tamil', 'Spanish', 'Hindi', 'Malayalam', 'French', 'Telugu', 'Chinese', 'German', 'Kannada', 'Italian', 'Portuguese', 'Marathi', 'Arabic', 'Russian', 'Japanese', 'Gujarati', 'Urdu', 'Bengali', 'Punjabi', 'Korean', 'Tagalog', 'Romanian', 'Vietnamese', 'Greek', 'Polish', 'Dutch', 'Turkish', 'Hebrew', 'Swedish', 'Serbian', 'Nepali', 'Bulgarian', 'Macedonian', 'Oriya']\n",
        "pavlick_langauge = ['English', 'Tamil', 'Malayalam', 'Hindi', 'Spanish', 'Telugu', 'Chinese', 'Romanian', 'Portuguese', 'Arabic', 'Kannada', 'German', 'French', 'Polish', 'Urdu', 'Tagalog', 'Marathi', 'Russian', 'Italian', 'Bengali', 'Gujarati', 'Hebrew', 'Dutch', 'Turkish', 'Vietnamese', 'Macedonian', 'Cebuano', 'Swedish', 'Bulgarian', 'Swahili', 'Hungarian', 'Catalan', 'Thai', 'Lithuanian', 'Punjabi']\n",
        "\n",
        "intersect_language = intersect(my_langauge, pavlick_langauge)\n",
        "len(intersect_language)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vw_JL1s2upq"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import spearmanr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKAvt-Ia2upq"
      },
      "outputs": [],
      "source": [
        "spearmanr(my_langauge,pavlick_langauge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJi6zH7i2upq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7kVV_ko2upq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}